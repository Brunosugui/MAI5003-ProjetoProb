{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation_train\n",
    "Este notebook é dedicado à parte de validação (cross-validation / hold-out validation), calculo do threshold ótimo e aplicação nos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the final dataframe from data_prep \n",
    "df_data = pd.read_csv('diabetic_data_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load columns to use from data_prep\n",
    "col2use = pd.read_csv('col2use.csv')\n",
    "col2use = col2use['col2use'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "5        1\n",
       "6        0\n",
       "7        0\n",
       "8        0\n",
       "9        0\n",
       "10       0\n",
       "11       0\n",
       "12       0\n",
       "13       0\n",
       "14       0\n",
       "15       0\n",
       "16       0\n",
       "17       0\n",
       "18       0\n",
       "19       1\n",
       "20       0\n",
       "21       0\n",
       "22       0\n",
       "23       0\n",
       "24       0\n",
       "25       0\n",
       "26       0\n",
       "27       0\n",
       "28       0\n",
       "29       0\n",
       "        ..\n",
       "99313    0\n",
       "99314    0\n",
       "99315    0\n",
       "99316    0\n",
       "99317    0\n",
       "99318    0\n",
       "99319    1\n",
       "99320    0\n",
       "99321    0\n",
       "99322    0\n",
       "99323    0\n",
       "99324    0\n",
       "99325    0\n",
       "99326    0\n",
       "99327    0\n",
       "99328    0\n",
       "99329    0\n",
       "99330    0\n",
       "99331    0\n",
       "99332    0\n",
       "99333    0\n",
       "99334    0\n",
       "99335    0\n",
       "99336    0\n",
       "99337    0\n",
       "99338    0\n",
       "99339    0\n",
       "99340    0\n",
       "99341    0\n",
       "99342    0\n",
       "Name: OUTPUT_LABEL, Length: 99343, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['OUTPUT_LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_in_hospital',\n",
       " 'num_lab_procedures',\n",
       " 'num_procedures',\n",
       " 'num_medications',\n",
       " 'number_outpatient',\n",
       " 'number_emergency',\n",
       " 'number_inpatient',\n",
       " 'number_diagnoses',\n",
       " 'race_Asian',\n",
       " 'race_Caucasian',\n",
       " 'race_Hispanic',\n",
       " 'race_Other',\n",
       " 'race_UNK',\n",
       " 'gender_Male',\n",
       " 'gender_Unknown/Invalid',\n",
       " 'max_glu_serum_>300',\n",
       " 'max_glu_serum_None',\n",
       " 'max_glu_serum_Norm',\n",
       " 'A1Cresult_>8',\n",
       " 'A1Cresult_None',\n",
       " 'A1Cresult_Norm',\n",
       " 'metformin_No',\n",
       " 'metformin_Steady',\n",
       " 'metformin_Up',\n",
       " 'repaglinide_No',\n",
       " 'repaglinide_Steady',\n",
       " 'repaglinide_Up',\n",
       " 'nateglinide_No',\n",
       " 'nateglinide_Steady',\n",
       " 'nateglinide_Up',\n",
       " 'chlorpropamide_No',\n",
       " 'chlorpropamide_Steady',\n",
       " 'chlorpropamide_Up',\n",
       " 'glimepiride_No',\n",
       " 'glimepiride_Steady',\n",
       " 'glimepiride_Up',\n",
       " 'acetohexamide_Steady',\n",
       " 'glipizide_No',\n",
       " 'glipizide_Steady',\n",
       " 'glipizide_Up',\n",
       " 'glyburide_No',\n",
       " 'glyburide_Steady',\n",
       " 'glyburide_Up',\n",
       " 'tolbutamide_Steady',\n",
       " 'pioglitazone_No',\n",
       " 'pioglitazone_Steady',\n",
       " 'pioglitazone_Up',\n",
       " 'rosiglitazone_No',\n",
       " 'rosiglitazone_Steady',\n",
       " 'rosiglitazone_Up',\n",
       " 'acarbose_No',\n",
       " 'acarbose_Steady',\n",
       " 'acarbose_Up',\n",
       " 'miglitol_No',\n",
       " 'miglitol_Steady',\n",
       " 'miglitol_Up',\n",
       " 'troglitazone_Steady',\n",
       " 'tolazamide_Steady',\n",
       " 'tolazamide_Up',\n",
       " 'insulin_No',\n",
       " 'insulin_Steady',\n",
       " 'insulin_Up',\n",
       " 'glyburide-metformin_No',\n",
       " 'glyburide-metformin_Steady',\n",
       " 'glyburide-metformin_Up',\n",
       " 'glipizide-metformin_Steady',\n",
       " 'glimepiride-pioglitazone_Steady',\n",
       " 'metformin-rosiglitazone_Steady',\n",
       " 'metformin-pioglitazone_Steady',\n",
       " 'change_No',\n",
       " 'diabetesMed_Yes',\n",
       " 'payer_code_CH',\n",
       " 'payer_code_CM',\n",
       " 'payer_code_CP',\n",
       " 'payer_code_DM',\n",
       " 'payer_code_FR',\n",
       " 'payer_code_HM',\n",
       " 'payer_code_MC',\n",
       " 'payer_code_MD',\n",
       " 'payer_code_MP',\n",
       " 'payer_code_OG',\n",
       " 'payer_code_OT',\n",
       " 'payer_code_PO',\n",
       " 'payer_code_SI',\n",
       " 'payer_code_SP',\n",
       " 'payer_code_UN',\n",
       " 'payer_code_UNK',\n",
       " 'payer_code_WC',\n",
       " 'admission_type_id_2',\n",
       " 'admission_type_id_3',\n",
       " 'admission_type_id_4',\n",
       " 'admission_type_id_5',\n",
       " 'admission_type_id_6',\n",
       " 'admission_type_id_7',\n",
       " 'admission_type_id_8',\n",
       " 'discharge_disposition_id_10',\n",
       " 'discharge_disposition_id_12',\n",
       " 'discharge_disposition_id_15',\n",
       " 'discharge_disposition_id_16',\n",
       " 'discharge_disposition_id_17',\n",
       " 'discharge_disposition_id_18',\n",
       " 'discharge_disposition_id_2',\n",
       " 'discharge_disposition_id_22',\n",
       " 'discharge_disposition_id_23',\n",
       " 'discharge_disposition_id_24',\n",
       " 'discharge_disposition_id_25',\n",
       " 'discharge_disposition_id_27',\n",
       " 'discharge_disposition_id_28',\n",
       " 'discharge_disposition_id_3',\n",
       " 'discharge_disposition_id_4',\n",
       " 'discharge_disposition_id_5',\n",
       " 'discharge_disposition_id_6',\n",
       " 'discharge_disposition_id_7',\n",
       " 'discharge_disposition_id_8',\n",
       " 'discharge_disposition_id_9',\n",
       " 'admission_source_id_10',\n",
       " 'admission_source_id_11',\n",
       " 'admission_source_id_13',\n",
       " 'admission_source_id_14',\n",
       " 'admission_source_id_17',\n",
       " 'admission_source_id_2',\n",
       " 'admission_source_id_20',\n",
       " 'admission_source_id_22',\n",
       " 'admission_source_id_25',\n",
       " 'admission_source_id_3',\n",
       " 'admission_source_id_4',\n",
       " 'admission_source_id_5',\n",
       " 'admission_source_id_6',\n",
       " 'admission_source_id_7',\n",
       " 'admission_source_id_8',\n",
       " 'admission_source_id_9',\n",
       " 'med_spec_Emergency/Trauma',\n",
       " 'med_spec_Family/GeneralPractice',\n",
       " 'med_spec_InternalMedicine',\n",
       " 'med_spec_Nephrology',\n",
       " 'med_spec_Orthopedics',\n",
       " 'med_spec_Orthopedics-Reconstructive',\n",
       " 'med_spec_Other',\n",
       " 'med_spec_Radiologist',\n",
       " 'med_spec_Surgery-General',\n",
       " 'med_spec_UNK',\n",
       " 'age_group',\n",
       " 'has_weight']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col2use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the samples\n",
    "df_data = df_data.sample(n = len(df_data), random_state = 42)\n",
    "df_data = df_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções \n",
    "\n",
    "Geral para analises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prevalence(y_actual):\n",
    "    return (sum(y_actual)/len(y_actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "def calc_specificity(y_actual, y_pred, thresh):\n",
    "    # calculates specificity\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
    "\n",
    "def print_report(y_actual, y_pred, thresh):\n",
    "    \n",
    "    auc = roc_auc_score(y_actual, y_pred)\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    specificity = calc_specificity(y_actual, y_pred, thresh)\n",
    "    print('AUC:%.3f'%auc)\n",
    "    print('accuracy:%.3f'%accuracy)\n",
    "    print('recall:%.3f'%recall)\n",
    "    print('precision:%.3f'%precision)\n",
    "    print('specificity:%.3f'%specificity)\n",
    "    print('prevalence:%.3f'%calc_prevalence(y_actual))\n",
    "    print(' ')\n",
    "    return auc, accuracy, recall, precision, specificity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, \\\n",
    "                            average_precision_score, f1_score, precision_score,\\\n",
    "                            recall_score, roc_auc_score, log_loss, confusion_matrix\n",
    "\n",
    "def report(y_true, y_pred, prefix):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    ap      = average_precision_score(y_true, y_pred)\n",
    "    f1      = f1_score(y_true, y_pred)\n",
    "    lloss   = log_loss(y_true, y_pred)\n",
    "    prec    = precision_score(y_true, y_pred)\n",
    "    recall  = recall_score(y_true, y_pred)\n",
    "    auc     = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    print ('{} Accuracy :{:3}'.format(prefix, accuracy))\n",
    "    print ('{} AP:       {:3}'.format(prefix, ap))\n",
    "    print ('{} F1-score :{:3}'.format(prefix, f1))\n",
    "    print ('{} Log-Loss :{:3}'.format(prefix, lloss))\n",
    "    print ('{} Precision:{:3}'.format(prefix, prec))\n",
    "    print ('{} Recall   :{:3}'.format(prefix, recall))\n",
    "    print ('{} AUC      :{:3}'.format(prefix, auc))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def make_confusion_matrix(y_true, y_pred, names, normalized, prefix='', path=''):\n",
    "    \n",
    "    title = 'Confusion Matrix'\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "     \n",
    "    if normalized:\n",
    "        cm = cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=names, \n",
    "           yticklabels=names,\n",
    "           ylabel='True Label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right',\n",
    "                                   rotation_mode='anchor')\n",
    "    \n",
    "    fmt = '.2f' if normalized else 'd'\n",
    "    thresh = cm.max()/2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha='center', va='center',\n",
    "                    color='green')#'white' if cm[i,j] > thresh else 'black')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if path != '':\n",
    "        plt.savefig(path)\n",
    "        \n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall_specificity(y_actual, y_pred, thresh):\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    specificity = calc_specificity(y_actual, y_pred, thresh)\n",
    "    return [recall, (1-specificity)]\n",
    "\n",
    "def get_thresh_opt(y_actual, y_pred):\n",
    "    dist = []\n",
    "    for th in np.linspace(0, 1, 100):\n",
    "        a = get_recall_specificity(y_actual, y_pred, th)\n",
    "        dist.append([np.sqrt(np.power(a - np.array([0,1]), 2).sum()), th, a[0],a[1]])\n",
    "    dist = np.array(dist)\n",
    "    i_th_max = np.argmin(dist[:, 0])\n",
    "    th_max = dist[i_th_max, 1]\n",
    "    plt.plot(dist[:, 3], dist[:, 2])\n",
    "    plt.title('recall x (1-specificity)')\n",
    "    plt.xlabel('1 - specificity')\n",
    "    plt.ylabel('recall')\n",
    "    plt.show()\n",
    "    print('threshold ótimo: %f' %th_max)\n",
    "    return th_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#print da matriz de confusao e classification report do sklearn\n",
    "def get_analysis(y_valid, y_valid_preds, thresh):\n",
    "    y_valid_preds = y_valid_preds > thresh\n",
    "    print('SKLearn Classification Report')\n",
    "    print(classification_report(y_valid, y_valid_preds))\n",
    "    print('Matriz de Confusão')\n",
    "    print(confusion_matrix(y_valid, y_valid_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation methods\n",
    "\n",
    "Fazer aqui o estudo do cross-validation e hold-out validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho (relativo) dos dados utilizados para teste e treino: 0.300\n",
      "14902 14901\n",
      "69540\n",
      "all samples (n = 99343)\n"
     ]
    }
   ],
   "source": [
    "# pega 30% dos dados totais e usa como dados para teste e validação \n",
    "df_valid_test=df_data.sample(frac=0.30,random_state=42)\n",
    "print('Tamanho (relativo) dos dados utilizados para teste e treino: %.3f'%(len(df_valid_test)/len(df_data)))\n",
    "\n",
    "# divide os dados de df_valid_test em 50% teste e 50% validação\n",
    "df_test = df_valid_test.sample(frac = 0.5, random_state = 42)\n",
    "df_valid = df_valid_test.drop(df_test.index)\n",
    "\n",
    "print (len(df_test), len(df_valid))\n",
    "# usa o restante dos dados como dados de treino\n",
    "df_train_all=df_data.drop(df_valid_test.index)\n",
    "print (len(df_train_all))\n",
    "\n",
    "# verifica prevalência de cada dataframe\n",
    "#print('Test prevalence(n = %d):%.3f'%(len(df_test),calc_prevalence(df_test.OUTPUT_LABEL.values)))\n",
    "#print('Valid prevalence(n = %d):%.3f'%(len(df_valid),calc_prevalence(df_valid.OUTPUT_LABEL.values)))\n",
    "#print('Train all prevalence(n = %d):%.3f'%(len(df_train_all), calc_prevalence(df_train_all.OUTPUT_LABEL.values)))\n",
    "\n",
    "# verifica se todos os dados foram utilizados\n",
    "print('all samples (n = %d)'%len(df_data))\n",
    "assert len(df_data) == (len(df_test)+len(df_valid)+len(df_train_all)),'math didnt work'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you might say, drop the training data into a predictive model and see the outcome. However, if we do this, it is possible that we will get back a model that is 89% accurate. Great! Good job! But wait, we never catch any of the readmissions (recall= 0%). How can this happen?\n",
    "\n",
    "What is happening is that we have an imbalanced dataset where there are much more negatives than positives, so the model might just assigns all samples as negative.\n",
    "\n",
    "Typically, it is better to balance the data in some way to give the positives more weight. There are 3 strategies that are typically utilized:\n",
    "\n",
    "- sub-sample the more dominant class: use a random subset of the negatives\n",
    "- over-sample the imbalanced class: use the same positive samples multiple times\n",
    "- create synthetic positive data\n",
    "Usually, you will want to use the latter two methods if you only have a handful of positive cases. Since we have a few thousand positive cases, let's use the sub-sample approach. Here, we will create a balanced training data set that has 50% positive and 50% negative. You can also play with this ratio to see if you can get an improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "69540 7883 61657\n",
      "15766\n"
     ]
    }
   ],
   "source": [
    "# criação do dataframe de treino 50% positivo e negativo\n",
    "# split the training data into positive and negative\n",
    "rows_pos = df_train_all['OUTPUT_LABEL'] == 1\n",
    "df_train_pos = df_train_all.loc[rows_pos]\n",
    "df_train_neg = df_train_all.loc[~rows_pos]\n",
    "\n",
    "print (np.unique(df_train_all['OUTPUT_LABEL']))\n",
    "print (len(df_train_all), len(df_train_pos), len(df_train_neg))\n",
    "# merge the balanced data\n",
    "df_train = pd.concat([df_train_pos, df_train_neg.sample(n = len(df_train_pos), random_state = 42)],axis = 0)\n",
    "\n",
    "# shuffle the order of training samples \n",
    "df_train = df_train.sample(n = len(df_train), random_state = 42).reset_index(drop = True)\n",
    "print (len(df_train))\n",
    "\n",
    "#print('Train balanced prevalence(n = %d):%.3f'%(len(df_train), calc_prevalence(df_train.OUTPUT_LABEL.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_data.columns))\n",
    "print(len(col2use))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos dados de treino e validação para os modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15766\n",
      "Training All shapes: (69540, 143)\n",
      "Training shapes: (15766, 143) (15766,)\n",
      "Validation shapes: (14901, 143) (14901,)\n",
      "[ 3 53  5 18  0  0  0  9  0  0  0  0  1  1  0  0  1  0  0  1  0  1  0  0\n",
      "  1  0  0  1  0  0  1  0  0  1  0  0  0  1  0  0  1  0  0  0  1  0  0  1\n",
      "  0  0  1  0  0  1  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  1 60  0]\n"
     ]
    }
   ],
   "source": [
    "print (len(df_train))\n",
    "X_train = df_train[col2use].values\n",
    "X_train_all = df_train_all[col2use].values\n",
    "X_valid = df_valid[col2use].values\n",
    "\n",
    "y_train = df_train['OUTPUT_LABEL'].values\n",
    "y_valid = df_valid['OUTPUT_LABEL'].values\n",
    "\n",
    "print('Training All shapes:',X_train_all.shape)\n",
    "print('Training shapes:',X_train.shape, y_train.shape)\n",
    "print('Validation shapes:',X_valid.shape, y_valid.shape)\n",
    "print (X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# normalização dos dados para alguns modelos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler  = StandardScaler()\n",
    "scaler.fit(X_train_all)\n",
    "\n",
    "X_train_tf = scaler.transform(X_train)\n",
    "X_valid_tf = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Training:\n",
      "AUC:0.681\n",
      "accuracy:0.631\n",
      "recall:0.591\n",
      "precision:0.642\n",
      "specificity:0.670\n",
      "prevalence:0.500\n",
      " \n",
      "Validation:\n",
      "AUC:0.648\n",
      "accuracy:0.631\n",
      "recall:0.577\n",
      "precision:0.169\n",
      "specificity:0.638\n",
      "prevalence:0.113\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(max_depth = 6, random_state = 42)\n",
    "rf.fit(X_train_tf, y_train)\n",
    "\n",
    "y_train_preds = rf.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = rf.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "thresh = 0.5\n",
    "\n",
    "print('Random Forest')\n",
    "print('Training:')\n",
    "rf_train_auc, rf_train_accuracy, rf_train_recall, rf_train_precision, rf_train_specificity =print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "rf_valid_auc, rf_valid_accuracy, rf_valid_recall, rf_valid_precision, rf_valid_specificity = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold ótimo para os dados obtidos do modelo e analise\n",
    "thresh_opt = get_thresh_opt(y_valid,y_valid_preds)\n",
    "get_analysis(y_valid,y_valid_preds, thresh_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "report() missing 1 required positional argument: 'prefix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-e75b5c95d49b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmake_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: report() missing 1 required positional argument: 'prefix'"
     ]
    }
   ],
   "source": [
    "report(y_valid, y_valid_preds)\n",
    "#make_confusion_matrix(y_valid, y_valid_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors = 100)\n",
    "knn.fit(X_train_tf, y_train)\n",
    "\n",
    "y_train_preds = knn.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = knn.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('KNN')\n",
    "print('Training:')\n",
    "knn_train_auc, knn_train_accuracy, knn_train_recall, \\\n",
    "    knn_train_precision, knn_train_specificity = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "knn_valid_auc, knn_valid_accuracy, knn_valid_recall, \\\n",
    "    knn_valid_precision, knn_valid_specificity = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold ótimo para os dados obtidos do modelo e analise\n",
    "thresh_opt = get_thresh_opt(y_valid,y_valid_preds)\n",
    "get_analysis(y_valid,y_valid_preds, thresh_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(random_state = 42)\n",
    "lr.fit(X_train_tf, y_train)\n",
    "\n",
    "y_train_preds = lr.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = lr.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Logistic Regression')\n",
    "print('Training:')\n",
    "lr_train_auc, lr_train_accuracy, lr_train_recall, \\\n",
    "    lr_train_precision, lr_train_specificity = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold ótimo para os dados obtidos do modelo e analise\n",
    "thresh_opt = get_thresh_opt(y_valid,y_valid_preds)\n",
    "get_analysis(y_valid,y_valid_preds, thresh_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgdc=SGDClassifier(loss = 'log',alpha = 0.1,random_state = 42)\n",
    "sgdc.fit(X_train_tf, y_train)\n",
    "\n",
    "y_train_preds = sgdc.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = sgdc.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Stochastic Gradient Descend')\n",
    "print('Training:')\n",
    "sgdc_train_auc, sgdc_train_accuracy, sgdc_train_recall, sgdc_train_precision, sgdc_train_specificity =print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "sgdc_valid_auc, sgdc_valid_accuracy, sgdc_valid_recall, sgdc_valid_precision, sgdc_valid_specificity = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold ótimo para os dados obtidos do modelo e analise\n",
    "thresh_opt = get_thresh_opt(y_valid,y_valid_preds)\n",
    "get_analysis(y_valid,y_valid_preds, thresh_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_tf, y_train)\n",
    "\n",
    "y_train_preds = nb.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = nb.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Naive Bayes')\n",
    "print('Training:')\n",
    "nb_train_auc, nb_train_accuracy, nb_train_recall, nb_train_precision, nb_train_specificity =print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "nb_valid_auc, nb_valid_accuracy, nb_valid_recall, nb_valid_precision, nb_valid_specificity = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold ótimo para os dados obtidos do modelo e analise\n",
    "thresh_opt = get_thresh_opt(y_valid,y_valid_preds)\n",
    "get_analysis(y_valid,y_valid_preds, thresh_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc =GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "     max_depth=3, random_state=42)\n",
    "gbc.fit(X_train_tf, y_train)\n",
    "\n",
    "y_train_preds = gbc.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = gbc.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "print('Gradient Boosting Classifier')\n",
    "print('Training:')\n",
    "gbc_train_auc, gbc_train_accuracy, gbc_train_recall, gbc_train_precision, gbc_train_specificity = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "gbc_valid_auc, gbc_valid_accuracy, gbc_valid_recall, gbc_valid_precision, gbc_valid_specificity = print_report(y_valid,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold ótimo para os dados obtidos do modelo e analise\n",
    "thresh_opt = get_thresh_opt(y_valid,y_valid_preds)\n",
    "get_analysis(y_valid,y_valid_preds, thresh_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
